{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Docker Project: Frontend and Backend Setup Overview\n",
    "\n",
    "#### Project Structure\n",
    "\n",
    "In this project, you are provided with two main components located in different directories:\n",
    "1. **Backend Directory**: Contains a FastAPI application designed to serve machine learning models (pre-trained Torch `.t7` models). The backend processes images and applies a style transfer using OpenCV and the models loaded into memory.\n",
    "2. **Frontend Directory**: This is a Streamlit application that provides a user interface for uploading images and selecting styles. It sends requests to the backend to apply the selected style to the uploaded image and then displays the result.\n",
    "\n",
    "Take a moment to **explore the directories**:\n",
    "- **`backend/`**: Here, you’ll find the FastAPI app (`main.py`), configuration files (`config.py`), and the inference logic (`inference.py`).\n",
    "- **`frontend/`**: This contains the Streamlit app (`main.py`), which serves as the user interface for the style transfer service.\n",
    "\n",
    "#### Objective\n",
    "\n",
    "Your goal is to:\n",
    "1. Build two separate Docker images—one for the **backend** and one for the **frontend**.\n",
    "2. Run each application as an isolated container and see if the two applications can communicate with each other.\n",
    "\n",
    "---\n",
    "\n",
    "### Step-by-Step Instructions\n",
    "\n",
    "#### 0. **Download the models**\n",
    "\n",
    "- **Either** copy the previous models folder from `2-dsc_streamlit/streamlit/models` to `backend/models`.\n",
    "- **Or** Run the download_models.sh again.\n",
    "\n",
    "#### 1. **Build the Docker Images**\n",
    "\n",
    "You will start by building Docker images for the backend and frontend.\n",
    "\n",
    "- **Backend**: Tag the backend image as `fhtw-ai-backend`.\n",
    "- **Frontend**: Tag the frontend image as `fhtw-ai-frontend`.\n",
    "\n",
    "\n",
    "#### 2. **Run the Docker Containers**\n",
    "\n",
    "Next, run each image as its own Docker container.\n",
    "\n",
    "- **Run the backend container on port 8080**:\n",
    "- **Run the frontend container on port 80**:\n",
    "\n",
    "---\n",
    "\n",
    "### Test the Communication\n",
    "\n",
    "Once both containers are running:\n",
    "- Try accessing the frontend application in your browser.\n",
    "- Try accessing the backend application in your browser.\n",
    "- Try using the fastAPI that should be capable of running model inference.\n",
    "- The frontend should send requests to the backend.\n",
    "\n",
    "**Question**: Can the frontend communicate with the backend? \n",
    "\n",
    "If not, why do you think this is happening?\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
